import argparse

import gcsfs
import pandas as pd
from tqdm import tqdm


# This script generates replicate to sample mapping file to interpret the qc report. It
# was developed as an alternative to extract_rep_names_from_encode.sh which might not
# work if the pipeline run_dir had outputs for a specific condition in multiple
# workflow ids, this happens when a workflow is rerun on gcp, where the metadata.json
# file generated by caper points to the completed paths from failed workflow ids. This
# script uses the c roo.filetable.*.tsv to generate the mapping file

# Usage: python3 encode_rep_names_from_croo.py
# <gcp_path_to_croo_outputs> <gcp_output_bucket_path>
# <filelist_of_workflow_ids_in_the_batch> <gcp_project>


def main(gcp_path: str, output_path: str, workflow_id_fp: str, gcp_project: str):
    fs = gcsfs.GCSFileSystem(project=gcp_project)
    wfl = [line.strip() for line in open(workflow_id_fp, "r")]

    cond_l = []
    rep_l = []

    sample_list = []

    for i in (pbar := tqdm(wfl)):
        workflow_path = f"{gcp_path.rstrip('/')}/{i}"
        pbar.set_description(f"Processing {i} at {workflow_path}")

        in_path = fs.glob(f"{workflow_path}/**/croo.filetable*.tsv")
        pbar.write(f"Found {len(in_path)} filetable files: {in_path}")

        if len(in_path) == 0:
            print(f"Skip {i} since no filetable found or exit script?")
            print(f"Enter y/n")
            user_input = input()
            user_input = user_input.lower()
            if user_input == "y" or user_input == "yes":
                continue
            else:
                exit()

        filetable_filename = f"gs://{in_path[0]}"

        df_in = pd.read_csv(filetable_filename, sep="\t", header=None)
        filtered = df_in[df_in[0].str.contains("Raw BAM from aligner")]

        cond = filetable_filename.split("/")[-2]

        for vals in filtered[1]:
            split_vals = vals.split("/")
            cond_l.append(cond)
            rep = split_vals[-2]
            rep_l.append(rep)
            sample = (split_vals[-1]).split("_R1.trim.bam")[0]
            sample_list.append(sample)

        pbar.write(f"Found {len(filtered[1])} values, finished {i}\n")

    out_df = pd.DataFrame()
    out_df["cond_l"] = cond_l
    out_df["rep_l"] = rep_l
    out_df["sample_list"] = sample_list

    print(out_df.head())
    out_file = f"{output_path.rstrip('/')}/rep_to_sample_map.csv"
    out_df.to_csv(out_file, index=False, header=False)

    print("Success! Finished writing the mapping file")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="This script generates the replicate to sample mapping file to "
        "interpret the qc report"
    )
    parser.add_argument("gcp_path", help="location of atac-seq croo outputs", type=str)
    parser.add_argument(
        "output_path",
        help="output path, where you want the outputs to be written",
        type=str,
    )
    parser.add_argument(
        "wfids",
        help="file containing list of workflow ids,usually all workflows for a specific "
             "tissue",
    )
    parser.add_argument("gcp_project", help="file containing list of workflow ids")

    args = parser.parse_args()

    main(args.gcp_path, args.output_path, args.wfids, args.gcp_project)
